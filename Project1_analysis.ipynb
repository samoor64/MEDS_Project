{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvttbl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5cb5904983cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticomp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_tukeyhsd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticomp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiComparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyvttbl\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyvttbl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import pyvttbl as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(json_file):\n",
    "    category_dict = defaultdict(int)\n",
    "    with open (json_file) as file:\n",
    "        response = json.load(file)\n",
    "        for item in response['items']:\n",
    "            category_dict[item['id']] = item['snippet']['title']\n",
    "        return category_dict\n",
    "category_us = get_category(\"US_category_id.json\")\n",
    "category_gb = get_category(\"GB_category_id.json\")\n",
    "category_ca = get_category(\"CA_category_id.json\")\n",
    "category_de = get_category(\"DE_category_id.json\")\n",
    "category_fr = get_category(\"FR_category_id.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Function Top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV\n",
    "us = pd.read_csv(\"USvideos.csv\")\n",
    "gb = pd.read_csv(\"GBvideos.csv\")\n",
    "ca = pd.read_csv(\"CAvideos.csv\")\n",
    "de = pd.read_csv(\"DEvideos.csv\")\n",
    "fr = pd.read_csv(\"FRvideos.csv\")\n",
    "\n",
    "#Function for converting CSV into Top50 by month\n",
    "def raw_to_top50(df, category_file):\n",
    "    df['trending_date'] = pd.to_datetime(df['trending_date'], format = '%y.%d.%m')\n",
    "    df['trending_YearMonth'] = df['trending_date'].apply(lambda x: f'{x.year}-{x.month}')\n",
    "    df['publish_time'] = pd.to_datetime(df['publish_time'], format = '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    count_byMonth = df.groupby(['trending_YearMonth','title','category_id'])['video_id','views'].count() \n",
    "    top50_byMonth = count_byMonth['video_id'].groupby(level=0, group_keys=False).nlargest(50)\n",
    "    top50_byMonth = pd.DataFrame(top50_byMonth)\n",
    "    top50_byMonth = top50_byMonth.rename(columns={'video_id':'video_id_count'})\n",
    "    top50_byMonth = top50_byMonth.reset_index()\n",
    "    top50_byMonth['category_id'] = top50_byMonth['category_id'].astype(str)\n",
    "    top50_byMonth['category'] = top50_byMonth['category_id'].map(lambda x: category_file.get(x))\n",
    "    return top50_byMonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_top50_byMonth = raw_to_top50(us, category_us)\n",
    "us_top50_byMonth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_top50_byMonth = raw_to_top50(gb, category_gb)\n",
    "gb_top50_byMonth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_top50_byMonth = raw_to_top50(ca, category_ca)\n",
    "ca_top50_byMonth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_top50_byMonth = raw_to_top50(de, category_de)\n",
    "de_top50_byMonth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_top50_byMonth = raw_to_top50(fr, category_fr)\n",
    "fr_top50_byMonth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count of Trending Days: Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['2017-11','2017-12','2018-1','2018-2','2018-3','2018-4','2018-5','2018-6']\n",
    "for month in months:\n",
    "    us = us_top50_byMonth.loc[us_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    gb = gb_top50_byMonth.loc[gb_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    ca = ca_top50_byMonth.loc[ca_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    de = de_top50_byMonth.loc[de_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    fr = fr_top50_byMonth.loc[fr_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    plt.figure(figsize=(20,25))\n",
    "    plt.suptitle(f'Number of Trending Days in {month}', fontsize=20)\n",
    "    plt.subplot(5,1,1,)\n",
    "    plt.bar(np.arange(50),us['video_id_count'])\n",
    "    plt.title('US', fontsize=14)\n",
    "    plt.xticks(np.arange(50),np.arange(1,51,1))\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks(np.arange(0,35,5),[0,5,10,15,20,25,30])\n",
    "    plt.ylabel('Number Trending Days', fontsize=14)\n",
    "    plt.subplot(5,1,2)\n",
    "    plt.bar(np.arange(50),gb['video_id_count'])\n",
    "    plt.title('GB', fontsize=14)\n",
    "    plt.xticks(np.arange(50),np.arange(1,51,1))\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks(np.arange(0,35,5),[0,5,10,15,20,25,30])\n",
    "    plt.ylabel('Number Trending Days', fontsize=14)\n",
    "    plt.subplot(5,1,3)  \n",
    "    plt.bar(np.arange(50),ca['video_id_count'])\n",
    "    plt.title('CA', fontsize=14)\n",
    "    plt.xticks(np.arange(50),np.arange(1,51,1))\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks(np.arange(0,35,5),[0,5,10,15,20,25,30])\n",
    "    plt.ylabel('Number Trending Days', fontsize=14)\n",
    "    plt.subplot(5,1,4)   \n",
    "    plt.bar(np.arange(50),de['video_id_count'])\n",
    "    plt.title('DE', fontsize=14)\n",
    "    plt.xticks(np.arange(50),np.arange(1,51,1))\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks(np.arange(0,35,5),[0,5,10,15,20,25,30])\n",
    "    plt.ylabel('Number Trending Days', fontsize=14)\n",
    "    plt.subplot(5,1,5)    \n",
    "    plt.bar(np.arange(50),fr['video_id_count'])\n",
    "    plt.xticks(np.arange(50),np.arange(1,51,1))\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks(np.arange(0,35,5),[0,5,10,15,20,25,30])\n",
    "    plt.title('FR', fontsize=14)\n",
    "    plt.ylabel('Number Trending Days', fontsize=14)\n",
    "    plt.savefig('Views_{month}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category Overlap across countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for month in months:\n",
    "    us_cat = us_top50_byMonth.loc[us_top50_byMonth['trending_YearMonth'] == month]['category'].value_counts()\n",
    "    gb_cat = gb_top50_byMonth.loc[gb_top50_byMonth['trending_YearMonth'] == month]['category'].value_counts()\n",
    "    ca_cat = ca_top50_byMonth.loc[ca_top50_byMonth['trending_YearMonth'] == month]['category'].value_counts()\n",
    "    de_cat = de_top50_byMonth.loc[de_top50_byMonth['trending_YearMonth'] == month]['category'].value_counts()\n",
    "    fr_cat = fr_top50_byMonth.loc[fr_top50_byMonth['trending_YearMonth'] == month]['category'].value_counts()\n",
    "    \n",
    "    # plot pie charts\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.suptitle(f'{month}')\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.pie(us_cat,labels = us_cat.index, explode = [.05 for x in np.arange(len(us_cat))], autopct = '%.0f%%', startangle = 45)\n",
    "    plt.axis('equal')\n",
    "    plt.title('US')\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.pie(gb_cat,labels = gb_cat.index, explode = [.05 for x in np.arange(len(gb_cat))], autopct = '%.0f%%', startangle = 45)\n",
    "    plt.axis('equal')\n",
    "    plt.title('GB')\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.pie(ca_cat,labels = ca_cat.index, explode = [.05 for x in np.arange(len(ca_cat))], autopct = '%.0f%%', startangle = 45)\n",
    "    plt.axis('equal')\n",
    "    plt.title('CA')\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.pie(de_cat,labels = de_cat.index, explode = [.05 for x in np.arange(len(de_cat))], autopct = '%.0f%%', startangle = 45)\n",
    "    plt.axis('equal')\n",
    "    plt.title('DE')\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.pie(fr_cat,labels = fr_cat.index, explode = [.05 for x in np.arange(len(fr_cat))], autopct = '%.0f%%', startangle = 45)\n",
    "    plt.axis('equal')\n",
    "    plt.title('FR')\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=1, hspace=None)\n",
    "    plt.savefig(f\"Pie_{month}.png\")\n",
    "    \n",
    "    # plot stacked bar charts\n",
    "    unique_cats = us_cat.index.append(gb_cat.index).append(ca_cat.index).append(de_cat.index).append(fr_cat.index).unique()\n",
    "    cats = {}\n",
    "    for key in unique_cats:\n",
    "        cats[key]=0\n",
    "    us_dict = us_cat.to_dict()\n",
    "    us_cats = cats.copy()\n",
    "    for item in us_dict:\n",
    "        us_cats[item]=us_cats[item]+us_dict[item]\n",
    "\n",
    "    gb_dict = gb_cat.to_dict()\n",
    "    gb_cats = cats.copy()\n",
    "    for item in gb_dict:\n",
    "        gb_cats[item]=gb_cats[item]+gb_dict[item] \n",
    "\n",
    "    ca_dict = ca_cat.to_dict()\n",
    "    ca_cats = cats.copy()\n",
    "    for item in ca_dict:\n",
    "        ca_cats[item]=ca_cats[item]+ca_dict[item] \n",
    "\n",
    "    de_dict = de_cat.to_dict()\n",
    "    de_cats = cats.copy()\n",
    "    for item in de_dict:\n",
    "        de_cats[item]=de_cats[item]+de_dict[item] \n",
    "        \n",
    "    fr_dict = fr_cat.to_dict()\n",
    "    fr_cats = cats.copy()\n",
    "    for item in fr_dict:\n",
    "        fr_cats[item]=fr_cats[item]+fr_dict[item] \n",
    "    \n",
    "    plt.figure(figsize = (25,6))\n",
    "    p1= plt.bar(np.arange(len(us_cats.keys())),us_cats.values())\n",
    "    plt.ylabel(\"Number of Videos\", fontsize = 12)\n",
    "    plt.xticks(np.arange(len(us_cats.keys())),list(us_cats.keys()),fontsize = 11)\n",
    "    plt.title(f\"Overlap in Categories of Top-20 Videos across Countries {month}\", fontsize = 14)\n",
    "    bottom_us = list(us_cats.values())\n",
    "    p2 = plt.bar(np.arange(len(gb_cats.keys())),gb_cats.values(), bottom=bottom_us)\n",
    "    bottom_gb = list(gb_cats.values())\n",
    "    bottom_us_gb = [sum(x) for x in zip(bottom_us,bottom_gb)]\n",
    "    p3 = plt.bar(np.arange(len(ca_cats.keys())),ca_cats.values(), bottom=bottom_us_gb)\n",
    "    bottom_ca = list(ca_cats.values())\n",
    "    bottom_us_gb_ca = [sum(x) for x in zip(bottom_us_gb,bottom_ca)]\n",
    "    p4 = plt.bar(np.arange(len(de_cats.keys())),de_cats.values(), bottom=bottom_us_gb_ca)\n",
    "    bottom_de = list(de_cats.values())\n",
    "    bottom_us_gb_ca_de = [sum(x) for x in zip(bottom_us_gb_ca,bottom_de)]\n",
    "    p5 = plt.bar(np.arange(len(fr_cats.keys())),fr_cats.values(), bottom=bottom_us_gb_ca_de)\n",
    "    plt.legend((p1,p2,p3,p4,p5),(\"US\",'GB','CA','DE','FR'))\n",
    "    plt.savefig(f\"stacked_bar_{month}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video overlap rates across countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(len(us_cats.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_gb=[]\n",
    "us_ca=[]\n",
    "us_de=[]\n",
    "us_fr=[]\n",
    "gb_ca=[]\n",
    "gb_de=[]\n",
    "gb_fr=[]\n",
    "ca_de=[]\n",
    "ca_fr=[]\n",
    "de_fr=[]\n",
    "\n",
    "for month in months:\n",
    "    us_title = us_top50_byMonth.loc[us_top50_byMonth['trending_YearMonth'] == month]['title']\n",
    "    gb_title = gb_top50_byMonth.loc[gb_top50_byMonth['trending_YearMonth'] == month]['title']\n",
    "    ca_title = ca_top50_byMonth.loc[ca_top50_byMonth['trending_YearMonth'] == month]['title']\n",
    "    de_title = de_top50_byMonth.loc[de_top50_byMonth['trending_YearMonth'] == month]['title']\n",
    "    fr_title = fr_top50_byMonth.loc[fr_top50_byMonth['trending_YearMonth'] == month]['title']\n",
    "\n",
    "    count = 0\n",
    "    for item in gb_title:\n",
    "        if item in list(us_title):\n",
    "            count = count + 1\n",
    "    us_gb_overlap = int(count/50*100)\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    for item in ca_title:\n",
    "        if item in list(us_title):\n",
    "            count = count + 1\n",
    "    us_ca_overlap = int(count/50*100)\n",
    " \n",
    "    \n",
    "    count = 0\n",
    "    for item in de_title:\n",
    "        if item in list(us_title):\n",
    "            count = count + 1\n",
    "    us_de_overlap = int(count/50*100)\n",
    "\n",
    "    count = 0\n",
    "    for item in fr_title:\n",
    "        if item in list(us_title):\n",
    "            count = count + 1\n",
    "    us_fr_overlap = int(count/50*100)\n",
    "\n",
    "    count = 0\n",
    "    for item in ca_title:\n",
    "        if item in list(gb_title):\n",
    "            count = count + 1\n",
    "    gb_ca_overlap = int(count/50*100)\n",
    "\n",
    "    count = 0\n",
    "    for item in de_title:\n",
    "        if item in list(gb_title):\n",
    "            count = count + 1\n",
    "    gb_de_overlap = int(count/50*100)\n",
    "    \n",
    "    count = 0\n",
    "    for item in fr_title:\n",
    "        if item in list(gb_title):\n",
    "            count = count + 1\n",
    "    gb_fr_overlap = int(count/50*100)\n",
    "\n",
    "    count = 0\n",
    "    for item in de_title:\n",
    "        if item in list(ca_title):\n",
    "            count = count + 1\n",
    "    ca_de_overlap = int(count/50*100)\n",
    "    \n",
    "    count = 0\n",
    "    for item in fr_title:\n",
    "        if item in list(ca_title):\n",
    "            count = count + 1\n",
    "    ca_fr_overlap = int(count/50*100)\n",
    "    \n",
    "    count = 0\n",
    "    for item in fr_title:\n",
    "        if item in list(de_title):\n",
    "            count = count + 1\n",
    "    de_fr_overlap = int(count/50*100)\n",
    "        \n",
    "    \n",
    "    countries = ['US','GB','CA','DE','FR']\n",
    "    us_overlaps = [us_gb_overlap,us_ca_overlap,us_de_overlap,us_fr_overlap]\n",
    "    us_mean = np.mean(us_overlaps)\n",
    "    us_yrr = stats.sem(us_overlaps)\n",
    "    gb_overlaps = [us_gb_overlap,gb_ca_overlap,gb_de_overlap,gb_fr_overlap]\n",
    "    gb_mean = np.mean(gb_overlaps)\n",
    "    gb_yrr = stats.sem(gb_overlaps)\n",
    "    ca_overlaps = [us_ca_overlap,gb_ca_overlap,ca_de_overlap,ca_fr_overlap]\n",
    "    ca_mean = np.mean(ca_overlaps)\n",
    "    ca_yrr = stats.sem(ca_overlaps)\n",
    "    de_overlaps = [us_de_overlap,gb_de_overlap,ca_de_overlap,de_fr_overlap]\n",
    "    de_mean = np.mean(de_overlaps)\n",
    "    de_yrr = stats.sem(de_overlaps)\n",
    "    fr_overlaps = [us_fr_overlap,gb_fr_overlap,ca_fr_overlap,de_fr_overlap]\n",
    "    fr_mean = np.mean(fr_overlaps)\n",
    "    fr_yrr = stats.sem(fr_overlaps)\n",
    "    all_yrr = [us_yrr, gb_yrr, ca_yrr, de_yrr, fr_yrr]\n",
    "    \n",
    "    plt.figure(figsize = (18,5))\n",
    "    plt.suptitle(f'{month}', fontsize = 16)\n",
    "    plt.subplot(1,5,1)\n",
    "    plt.bar(x=np.arange(4) ,height=us_overlaps, color='blue')\n",
    "    plt.xticks(np.arange(4),['GB','CA','DE','FR'])\n",
    "    plt.ylim(0,50)\n",
    "    plt.ylabel(\"Percent Overlap of Top 50 Videos\")\n",
    "    plt.title(\"US\")\n",
    "    plt.subplot(1,5,2)\n",
    "    plt.bar(x=np.arange(4),height=gb_overlaps, color='blue')\n",
    "    plt.xticks(np.arange(4),['US','CA','DE','FR'])\n",
    "    plt.title(\"GB\")\n",
    "    plt.ylim(0,50)\n",
    "    plt.subplot(1,5,3)\n",
    "    plt.bar(x=np.arange(4),height=ca_overlaps,color='blue')\n",
    "    plt.xticks(np.arange(4),['US','GB','DE','FR'])\n",
    "    plt.title(\"CA\")\n",
    "    plt.ylim(0,50)\n",
    "    plt.subplot(1,5,4)\n",
    "    plt.bar(x=np.arange(4),height=de_overlaps, color='blue')\n",
    "    plt.xticks(np.arange(4),['US','GB','CA','FR'])\n",
    "    plt.title(\"DE\")\n",
    "    plt.ylim(0,50)\n",
    "    plt.subplot(1,5,5)\n",
    "    plt.bar(x=np.arange(4),height=fr_overlaps, color='blue')\n",
    "    plt.xticks(np.arange(4),['US','GB','CA','DE'])\n",
    "    plt.title(\"FR\")\n",
    "    plt.ylim(0,50)\n",
    "    plt.savefig(f'Overlap_rate_countries_{month}.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.bar(np.arange(5),height=[us_mean,gb_mean,ca_mean,de_mean,fr_mean],yerr = all_yrr, color='purple')\n",
    "    plt.xticks(np.arange(5),['US','GB','CA','DE','FR'])\n",
    "    plt.ylabel(\"Average Percent Overlap\")\n",
    "    plt.title(f'{month}')\n",
    "    plt.ylim(0,50)\n",
    "    plt.annotate(f'{us_mean:.1f}',xy=(0-.15,us_mean +6))\n",
    "    plt.annotate(f'{gb_mean:.1f}',xy=(1-.15,gb_mean +6))\n",
    "    plt.annotate(f'{ca_mean:.1f}',xy=(2-.15,ca_mean +6))\n",
    "    plt.annotate(f'{de_mean:.1f}',xy=(3-.15,de_mean +6))\n",
    "    plt.annotate(f'{fr_mean:.1f}',xy=(4-.15,fr_mean +6))\n",
    "    plt.savefig(f'Overlap_rate_{month}.png')\n",
    "    \n",
    "    \n",
    "    anova_test = stats.f_oneway(us_overlaps, gb_overlaps, ca_overlaps, de_overlaps, fr_overlaps)\n",
    "    p_value = list(anova_test)[1]\n",
    "    if p_value <= .05:\n",
    "        overlap = us_overlaps + gb_overlaps + ca_overlaps + de_overlaps + fr_overlaps\n",
    "        country = ['us']*4+['gb']*4+['ca']*4+['de']*4+['fr']*4\n",
    "        df = pd.DataFrame({'Overlap': overlap, \n",
    "                          'Countries': country})\n",
    "        mc = MultiComparison(df['Overlap'],df['Countries'])\n",
    "        result = mc.tukeyhsd()\n",
    "        print(f'Post Hoc Analysis for {month}: {result}')\n",
    "    else:\n",
    "        print('No significant difference across the countries in overlap rates for {month}')\n",
    "    #get lists for paired-country analysis for all the months\n",
    "    \n",
    "    us_gb.append(us_gb_overlap)\n",
    "    us_ca.append(us_ca_overlap)\n",
    "    us_de.append(us_de_overlap)\n",
    "    us_fr.append(us_fr_overlap)\n",
    "    gb_ca.append(gb_ca_overlap)\n",
    "    gb_de.append(gb_ca_overlap)\n",
    "    gb_fr.append(gb_fr_overlap)\n",
    "    ca_de.append(ca_de_overlap)\n",
    "    ca_fr.append(ca_fr_overlap)\n",
    "    de_fr.append(de_fr_overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video overlap rates for country pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df for repeated ANOVA\n",
    "rates = us_gb + us_ca + us_de + us_fr + gb_ca + gb_de + gb_fr + ca_de + ca_fr + de_fr\n",
    "across_factor = np.repeat(['us_gb','us_ca','us_de','us_fr','gb_ca','gb_de','gb_fr','ca_de','ca_fr','de_fr'],8)\n",
    "within_factor = [1,2,3,4,5,6,7,8]*10\n",
    "repeated = pd.DataFrame({\n",
    "    \"Rates\": rates,\n",
    "    \"Across_factor\": across_factor,\n",
    "    \"Within_factor\": within_factor\n",
    "})\n",
    "\n",
    "# repeated ANOVA carried out in R (outside this notebook)\n",
    "# results: \n",
    "\n",
    "# Below it is ran as one_way ANOVA(non-repeated)\n",
    "#aov = repeated.anova('Rates', sub='Across_factor', wfactors=['Within_factor'])\n",
    "#print(aov)\n",
    "\n",
    "print(us_gb)\n",
    "print(us_ca)\n",
    "print(us_de)\n",
    "print(us_fr)\n",
    "print(gb_ca)\n",
    "print(gb_de)\n",
    "print(gb_fr)\n",
    "print(ca_de)\n",
    "print(ca_fr)\n",
    "print(de_fr)\n",
    "print(stats.f_oneway(us_gb,us_ca,us_de,us_fr,gb_ca,gb_de,gb_fr,ca_de,ca_fr,de_fr))\n",
    "mc = MultiComparison(repeated['Rates'],repeated['Across_factor'])\n",
    "result = mc.tukeyhsd()\n",
    "print(f'posthoc results: {result}')\n",
    "\n",
    "plt.figure(figsize=(30,25))\n",
    "plt.subplot(2,5,1)\n",
    "plt.bar(np.arange(8),us_gb)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('US_GB', fontsize = 24)\n",
    "plt.ylabel('Overlap Rates (percent)', fontsize =20)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,2)\n",
    "plt.bar(np.arange(8),us_ca)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('US_CA', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,3)\n",
    "plt.bar(np.arange(8),us_de)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('US_DE', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,4)\n",
    "plt.bar(np.arange(8),us_fr)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('US_FR', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,5)\n",
    "plt.bar(np.arange(8),gb_ca)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('GB_CA', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,6)\n",
    "plt.bar(np.arange(8),gb_de)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,102,20), fontsize = 14)\n",
    "plt.ylabel('Overlap Rates (percent)', fontsize =20)\n",
    "plt.title('GB_DE', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,7)\n",
    "plt.bar(np.arange(8),gb_fr)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('GB_FR', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,8)\n",
    "plt.bar(np.arange(8),ca_de)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('CA_DE', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,9)\n",
    "plt.bar(np.arange(8),ca_fr)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('CA_FR', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.subplot(2,5,10)\n",
    "plt.bar(np.arange(8),de_fr)\n",
    "plt.xticks(np.arange(8),months, rotation = 60, ha='right', fontsize=14)\n",
    "plt.yticks(np.arange(0,101,20), fontsize = 14)\n",
    "plt.title('DE_FR', fontsize = 24)\n",
    "plt.ylim(0,50)\n",
    "plt.savefig(\"Overlap_country_pairs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated.to_csv('repeated_ANOVA_df.csv')\n",
    "repeated.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Overlap Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in months:\n",
    "    us = us_top50_byMonth.loc[us_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    gb = gb_top50_byMonth.loc[gb_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    ca = ca_top50_byMonth.loc[ca_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    de = de_top50_byMonth.loc[de_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    fr = fr_top50_byMonth.loc[fr_top50_byMonth['trending_YearMonth']==month,:]\n",
    "    us_dict = dict(zip(us['title'],us['video_id_count']))\n",
    "    gb_dict = dict(zip(gb['title'],gb['video_id_count']))\n",
    "    ca_dict = dict(zip(ca['title'],ca['video_id_count']))\n",
    "    de_dict = dict(zip(de['title'],de['video_id_count']))\n",
    "    fr_dict = dict(zip(fr['title'],fr['video_id_count']))\n",
    "\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.scatter(np.arange(50),us_dict.values(), s = 20*(np.array(list(us_dict.values()))), color = 'purple')\n",
    "    plt.title(f'{month}_US')\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks([])\n",
    "    #plt.ylabel('Number of Trending Days')\n",
    "    plt.xlim(-2,51)\n",
    "    plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "    plt.savefig(f'Scatter_{month}_1.png')\n",
    "    \n",
    "    plt.show()\n",
    "    us_gb_dict = us_dict.copy()\n",
    "    for video in gb_dict.keys():\n",
    "        if video in us_gb_dict.keys():\n",
    "            us_gb_dict[video] = us_gb_dict[video] + gb_dict[video]\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.scatter(np.arange(50),us_dict.values(), s = 20*np.array(list(us_gb_dict.values())), color = 'purple')\n",
    "    plt.title(f'{month}_US_GB')\n",
    "    #plt.ylabel('Number of Trending Days')\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks([])\n",
    "    plt.xlim(-2,51)\n",
    "    plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "    plt.savefig(f'Scatter_{month}_2.png')\n",
    "    plt.show()\n",
    "    us_gb_ca_dict = us_gb_dict.copy()\n",
    "    for video in ca_dict.keys():\n",
    "        if video in us_gb_ca_dict.keys():\n",
    "            us_gb_ca_dict[video] = us_gb_ca_dict[video] + ca_dict[video]\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.scatter(np.arange(50),us_dict.values(), s = 20*np.array(list(us_gb_ca_dict.values())), color = 'purple')\n",
    "    plt.title(f'{month}_US_GB_CA')\n",
    "    #plt.ylabel('Number of Trending Days')\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks([])\n",
    "    plt.xlim(-2,51)\n",
    "    plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "    plt.savefig(f'Scatter_{month}_3.png')\n",
    "    plt.show()\n",
    "    us_gb_ca_de_dict = us_gb_ca_dict.copy()\n",
    "    for video in de_dict.keys():\n",
    "        if video in us_gb_ca_de_dict.keys():\n",
    "            us_gb_ca_de_dict[video] = us_gb_ca_de_dict[video] + de_dict[video]\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.scatter(np.arange(50),us_dict.values(), s = 20*np.array(list(us_gb_ca_de_dict.values())), color = 'purple')\n",
    "    plt.title(f'{month}_US_GB_CA_DE')\n",
    "    #plt.ylabel('Number of Trending Days')\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks([])\n",
    "    plt.xlim(-2,51)\n",
    "    plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "    plt.savefig(f'Scatter_{month}_4.png')\n",
    "    plt.show()\n",
    "    us_gb_ca_de_fr_dict = us_gb_ca_de_dict.copy()\n",
    "    for video in fr_dict.keys():\n",
    "        if video in us_gb_ca_de_fr_dict.keys():\n",
    "            us_gb_ca_de_fr_dict[video] = us_gb_ca_de_fr_dict[video] + fr_dict[video]\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.scatter(np.arange(50),us_dict.values(), s = 20*np.array(list(us_gb_ca_de_fr_dict.values())), color = 'purple')\n",
    "    plt.title(f'{month}_US_GB_CA_DE_FR')\n",
    "    #plt.ylabel('Number of Trending Days')\n",
    "    plt.ylim(0,31)\n",
    "    plt.yticks([])\n",
    "    plt.xlim(-2,51)\n",
    "    plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "    plt.savefig(f'Scatter_{month}_5.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us = us_top50_byMonth.loc[us_top50_byMonth['trending_YearMonth']=='2018-2',:]\n",
    "gb = gb_top50_byMonth.loc[gb_top50_byMonth['trending_YearMonth']=='2018-2',:]\n",
    "ca = ca_top50_byMonth.loc[ca_top50_byMonth['trending_YearMonth']=='2018-2',:]\n",
    "de = de_top50_byMonth.loc[de_top50_byMonth['trending_YearMonth']=='2018-2',:]\n",
    "fr = fr_top50_byMonth.loc[fr_top50_byMonth['trending_YearMonth']=='2018-2',:]\n",
    "us_dict = dict(zip(us['title'],us['video_id_count']))\n",
    "gb_dict = dict(zip(gb['title'],gb['video_id_count']))\n",
    "ca_dict = dict(zip(ca['title'],ca['video_id_count']))\n",
    "de_dict = dict(zip(de['title'],de['video_id_count']))\n",
    "fr_dict = dict(zip(fr['title'],fr['video_id_count']))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(np.arange(50),us_dict.values(), s = 40*(np.array(list(us_dict.values()))), color = 'purple')\n",
    "plt.title('2018-2_US')\n",
    "plt.ylim(0,31)\n",
    "plt.yticks([])\n",
    "#plt.ylabel('Number of Trending Days')\n",
    "plt.xlim(-2,51)\n",
    "plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "plt.savefig('Scatter_CountryPair_US_2018-2.png')\n",
    "plt.show()\n",
    "\n",
    "us_fr_dict = us_dict.copy()\n",
    "for video in fr_dict.keys():\n",
    "    if video in us_fr_dict.keys():\n",
    "        us_fr_dict[video] = us_fr_dict[video] + fr_dict[video]\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(np.arange(50),us_dict.values(), s = 40*np.array(list(us_fr_dict.values())), color = 'purple')\n",
    "plt.title('2018-2_US_FR')\n",
    "#plt.ylabel('Number of Trending Days')\n",
    "plt.ylim(0,31)\n",
    "plt.yticks([])\n",
    "plt.xlim(-2,51)\n",
    "plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "plt.savefig('Scatter_CountryPair_US_FR_2018-2.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(np.arange(50),ca_dict.values(), s = 50*(np.array(list(ca_dict.values()))), color = 'purple')\n",
    "plt.title('2018-2_CA')\n",
    "plt.ylim(0,31)\n",
    "plt.yticks([])\n",
    "#plt.ylabel('Number of Trending Days')\n",
    "plt.xlim(-2,51)\n",
    "plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "plt.savefig('Scatter_CountryPair_CA_2018-2.png')\n",
    "plt.show()\n",
    "\n",
    "ca_de_dict = ca_dict.copy()\n",
    "for video in de_dict.keys():\n",
    "    if video in ca_de_dict.keys():\n",
    "        ca_de_dict[video] = ca_de_dict[video] + de_dict[video]\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(np.arange(50),ca_dict.values(), s = 50*np.array(list(ca_de_dict.values())), color = 'purple')\n",
    "plt.title('2018-2_CA_DE')\n",
    "#plt.ylabel('Number of Trending Days')\n",
    "plt.ylim(0,31)\n",
    "plt.yticks([])\n",
    "plt.xlim(-2,51)\n",
    "plt.xticks(np.arange(50), np.arange(1,51,1))\n",
    "plt.savefig('Scatter_CountryPair_CA_DE_2018-2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
